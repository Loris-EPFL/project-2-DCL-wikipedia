{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb23c059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_link_prediction_dataset(df: pl.DataFrame, max_articles: int = None):\n",
    "    \"\"\"\n",
    "    Create unbiased training dataset for link prediction.\n",
    "    Input: Clean text without hyperlinks\n",
    "    Target: Links that should exist\n",
    "    \"\"\"\n",
    "    print(\"ğŸ¯ Creating unbiased link prediction dataset...\")\n",
    "    \n",
    "    # Use subset if specified\n",
    "    if max_articles:\n",
    "        df = df.head(max_articles)\n",
    "    \n",
    "    training_data = []\n",
    "    \n",
    "    for row in tqdm(df.iter_rows(named=True), total=len(df), desc=\"Processing articles\"):\n",
    "        source_id = row[\"id\"]\n",
    "        source_title = row[\"title\"]\n",
    "        clean_text = row[\"text_withoutHref\"]  # âœ… Clean text without links\n",
    "        actual_links = row.get(\"links\", []) or []  # âœ… Ground truth links\n",
    "        \n",
    "        # Extract target article IDs from links (ground truth)\n",
    "        target_ids = []\n",
    "        for link in actual_links:\n",
    "            href_decoded = link.get(\"href_decoded\", \"\")\n",
    "            # Map href to article ID (you'd need a URL->ID mapping)\n",
    "            target_id = map_href_to_article_id(href_decoded, df)\n",
    "            if target_id and target_id != source_id:\n",
    "                target_ids.append({\n",
    "                    \"target_id\": target_id,\n",
    "                    \"anchor_text\": link.get(\"anchor\", \"\"),\n",
    "                    \"position\": link.get(\"start_idx\", 0)\n",
    "                })\n",
    "        \n",
    "        training_data.append({\n",
    "            \"source_id\": source_id,\n",
    "            \"source_title\": source_title,\n",
    "            \"clean_text\": clean_text,  # Input: text without links\n",
    "            \"target_links\": target_ids,  # Labels: what links should exist\n",
    "            \"num_links\": len(target_ids)\n",
    "        })\n",
    "    \n",
    "    return pl.DataFrame(training_data)\n",
    "\n",
    "def map_href_to_article_id(href_decoded: str, df: pl.DataFrame):\n",
    "    \"\"\"Map Wikipedia href to article ID in our dataset\"\"\"\n",
    "    # Create title variations to match\n",
    "    variations = [\n",
    "        href_decoded,\n",
    "        href_decoded.replace(\"_\", \" \"),\n",
    "        href_decoded.replace(\"%20\", \" \"),\n",
    "        href_decoded.replace(\"_\", \"%20\")\n",
    "    ]\n",
    "    \n",
    "    for variation in variations:\n",
    "        matches = df.filter(pl.col(\"title\").str.to_lowercase() == variation.lower())\n",
    "        if matches.height > 0:\n",
    "            return matches.select(\"id\").to_series()[0]\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff52b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_article_similarity_features(df: pl.DataFrame, client, collection_name: str):\n",
    "    \"\"\"\n",
    "    Build features for link prediction using semantic similarity\n",
    "    WITHOUT using existing hyperlinks\n",
    "    \"\"\"\n",
    "    print(\"ğŸ§  Building semantic similarity features...\")\n",
    "    \n",
    "    features = []\n",
    "    \n",
    "    for row in tqdm(df.iter_rows(named=True), desc=\"Computing similarities\"):\n",
    "        source_id = row[\"id\"]\n",
    "        clean_text = row[\"text_withoutHref\"]\n",
    "        \n",
    "        # Encode the clean text (no hyperlinks)\n",
    "        try:\n",
    "            # Try to get from Qdrant first\n",
    "            similar_articles = client.recommend(\n",
    "                collection_name=collection_name,\n",
    "                positive=[int(source_id)],\n",
    "                limit=50,  # Get top 50 similar articles\n",
    "                with_payload=True\n",
    "            )\n",
    "        except:\n",
    "            # Fallback: encode the clean text\n",
    "            vec = encode_article_text(clean_text)\n",
    "            similar_articles = client.search(\n",
    "                collection_name=collection_name,\n",
    "                query_vector=vec,\n",
    "                limit=50\n",
    "            )\n",
    "        \n",
    "        # Create candidate links based on similarity\n",
    "        candidates = []\n",
    "        for result in similar_articles:\n",
    "            target_id = result.payload.get(\"id\", result.id)\n",
    "            if int(target_id) != int(source_id):\n",
    "                candidates.append({\n",
    "                    \"target_id\": target_id,\n",
    "                    \"similarity_score\": result.score,\n",
    "                    \"target_title\": result.payload.get(\"title\", \"\")\n",
    "                })\n",
    "        \n",
    "        features.append({\n",
    "            \"source_id\": source_id,\n",
    "            \"candidates\": candidates\n",
    "        })\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed9ba580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_samples(df: pl.DataFrame, similarity_features: list, negative_ratio: float = 2.0):\n",
    "    \"\"\"\n",
    "    Create positive and negative training samples for link prediction\n",
    "    \"\"\"\n",
    "    print(\"ğŸ“Š Creating positive/negative training samples...\")\n",
    "    \n",
    "    # Create mapping for fast lookup\n",
    "    id_to_links = {}\n",
    "    for row in df.iter_rows(named=True):\n",
    "        source_id = row[\"id\"]\n",
    "        actual_links = row.get(\"links\", []) or []\n",
    "        target_ids = set()\n",
    "        \n",
    "        for link in actual_links:\n",
    "            target_id = map_href_to_article_id(link.get(\"href_decoded\", \"\"), df)\n",
    "            if target_id:\n",
    "                target_ids.add(target_id)\n",
    "        \n",
    "        id_to_links[source_id] = target_ids\n",
    "    \n",
    "    training_samples = []\n",
    "    \n",
    "    for feature_row in tqdm(similarity_features, desc=\"Creating samples\"):\n",
    "        source_id = feature_row[\"source_id\"]\n",
    "        candidates = feature_row[\"candidates\"]\n",
    "        actual_targets = id_to_links.get(source_id, set())\n",
    "        \n",
    "        positive_samples = []\n",
    "        negative_samples = []\n",
    "        \n",
    "        for candidate in candidates:\n",
    "            target_id = candidate[\"target_id\"]\n",
    "            similarity_score = candidate[\"similarity_score\"]\n",
    "            \n",
    "            # Create feature vector\n",
    "            features = {\n",
    "                \"source_id\": source_id,\n",
    "                \"target_id\": target_id,\n",
    "                \"similarity_score\": similarity_score,\n",
    "                \"target_title\": candidate[\"target_title\"]\n",
    "            }\n",
    "            \n",
    "            if target_id in actual_targets:\n",
    "                # Positive sample - this link actually exists\n",
    "                features[\"label\"] = 1\n",
    "                positive_samples.append(features)\n",
    "            else:\n",
    "                # Negative sample - this link doesn't exist\n",
    "                features[\"label\"] = 0\n",
    "                negative_samples.append(features)\n",
    "        \n",
    "        # Balance positive/negative samples\n",
    "        num_negatives = min(len(negative_samples), int(len(positive_samples) * negative_ratio))\n",
    "        selected_negatives = negative_samples[:num_negatives]\n",
    "        \n",
    "        training_samples.extend(positive_samples)\n",
    "        training_samples.extend(selected_negatives)\n",
    "    \n",
    "    return pl.DataFrame(training_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9be4d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, precision_recall_curve\n",
    "import numpy as np\n",
    "\n",
    "def train_link_prediction_model(training_df: pl.DataFrame):\n",
    "    \"\"\"\n",
    "    Train a simple link prediction model\n",
    "    \"\"\"\n",
    "    print(\"ğŸ¤– Training link prediction model...\")\n",
    "    \n",
    "    # Prepare features and labels\n",
    "    X = training_df.select([\"similarity_score\"]).to_numpy()  # Start with just similarity\n",
    "    y = training_df.select(\"label\").to_numpy().flatten()\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train model\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    print(\"ğŸ“Š Model Performance:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return model, X_test, y_test, y_prob\n",
    "\n",
    "def predict_links_for_article(model, client, article_id: int, df: pl.DataFrame, k: int = 10):\n",
    "    \"\"\"\n",
    "    Predict top-k links for a given article using trained model\n",
    "    \"\"\"\n",
    "    # Get article info\n",
    "    article_row = df.filter(pl.col(\"id\") == article_id)\n",
    "    if article_row.height == 0:\n",
    "        print(f\"Article {article_id} not found\")\n",
    "        return\n",
    "    \n",
    "    article_title = article_row.select(\"title\").to_series()[0]\n",
    "    clean_text = article_row.select(\"text_withoutHref\").to_series()[0]\n",
    "    \n",
    "    print(f\"ğŸ”® Predicting links for: '{article_title}' (ID: {article_id})\")\n",
    "    \n",
    "    # Get similar articles (candidates)\n",
    "    try:\n",
    "        similar_articles = client.recommend(\n",
    "            collection_name=\"wikipedia_fr\",\n",
    "            positive=[int(article_id)],\n",
    "            limit=100,\n",
    "            with_payload=True\n",
    "        )\n",
    "    except:\n",
    "        vec = encode_article_text(clean_text)\n",
    "        similar_articles = client.search(\n",
    "            collection_name=\"wikipedia_fr\",\n",
    "            query_vector=vec,\n",
    "            limit=100\n",
    "        )\n",
    "    \n",
    "    # Predict for each candidate\n",
    "    predictions = []\n",
    "    for result in similar_articles:\n",
    "        target_id = result.payload.get(\"id\", result.id)\n",
    "        if int(target_id) != int(article_id):\n",
    "            # Create feature vector\n",
    "            features = np.array([[result.score]])  # Just similarity for now\n",
    "            \n",
    "            # Predict probability\n",
    "            prob = model.predict_proba(features)[0][1]\n",
    "            \n",
    "            predictions.append({\n",
    "                \"target_id\": target_id,\n",
    "                \"target_title\": result.payload.get(\"title\", \"\"),\n",
    "                \"similarity_score\": result.score,\n",
    "                \"link_probability\": prob\n",
    "            })\n",
    "    \n",
    "    # Sort by link probability and return top-k\n",
    "    predictions.sort(key=lambda x: x[\"link_probability\"], reverse=True)\n",
    "    \n",
    "    print(f\"\\nğŸ¯ Top {k} predicted links:\")\n",
    "    for i, pred in enumerate(predictions[:k]):\n",
    "        print(f\"{i+1:2d}. '{pred['target_title']}' (ID: {pred['target_id']})\")\n",
    "        print(f\"     Similarity: {pred['similarity_score']:.3f}, Link Prob: {pred['link_probability']:.3f}\")\n",
    "    \n",
    "    return predictions[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caa6e193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import PointStruct, VectorParams\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "#If you already saved the model locally and are using docker\n",
    "client = QdrantClient(host=\"localhost\", port=6333, prefer_grpc=True)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SentenceTransformer(\"models/multilingual-e5-large\", device=device)\n",
    "\n",
    "# Run docker container before\n",
    "# docker run -d --name qdrant -p 6333:6333 -p 6334:6334 -v /home/Loris/EPFL/MA3/ML/project2/project2Rag/qdrant_storage:/qdrant/storage qdrant/qdrant:latest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58b2fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "\n",
    "df = pl.read_parquet(\"articles_fr_merged.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c82cbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 6)\n",
      "â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ id  â”† title             â”† text              â”† links             â”† link_count â”† text_withoutHref  â”‚\n",
      "â”‚ --- â”† ---               â”† ---               â”† ---               â”† ---        â”† ---               â”‚\n",
      "â”‚ i64 â”† str               â”† str               â”† list[struct[5]]   â”† u32        â”† str               â”‚\n",
      "â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 3   â”† Antoine Meillet   â”† Antoine Meillet,  â”† [{\"https://fr.wik â”† 65         â”† Antoine Meillet,  â”‚\n",
      "â”‚     â”†                   â”† nÃ© le Ã  &lt;aâ€¦    â”† ipedia.org/wiâ€¦    â”†            â”† nÃ© le Ã  Mouliâ€¦    â”‚\n",
      "â”‚ 7   â”† AlgÃ¨bre linÃ©aire  â”† Lâ€™algÃ¨bre         â”† [{\"https://fr.wik â”† 111        â”† Lâ€™algÃ¨bre         â”‚\n",
      "â”‚     â”†                   â”† linÃ©aire est la   â”† ipedia.org/wiâ€¦    â”†            â”† linÃ©aire est la   â”‚\n",
      "â”‚     â”†                   â”† branâ€¦             â”†                   â”†            â”† branâ€¦             â”‚\n",
      "â”‚ 9   â”† AlgÃ¨bre gÃ©nÃ©rale  â”† L'&lt;a href=\"alg â”† [{\"https://fr.wik â”† 15         â”† L'algÃ¨bre         â”‚\n",
      "â”‚     â”†                   â”† %C3%A8bre\"&gtâ€¦    â”† ipedia.org/wiâ€¦    â”†            â”† gÃ©nÃ©rale, ou      â”‚\n",
      "â”‚     â”†                   â”†                   â”†                   â”†            â”† algÃ¨breâ€¦          â”‚\n",
      "â”‚ 10  â”† Algorithmique     â”† L'algorithmique   â”† [{\"https://fr.wik â”† 101        â”† L'algorithmique   â”‚\n",
      "â”‚     â”†                   â”† est l'Ã©tude etâ€¦   â”† ipedia.org/wiâ€¦    â”†            â”† est l'Ã©tude etâ€¦   â”‚\n",
      "â”‚ 11  â”† Politique en      â”† L'&lt;a href=\"Arg â”† [{\"https://fr.wik â”† 78         â”† L'Argentine est   â”‚\n",
      "â”‚     â”† Argentine         â”† entine\"&gt;Arâ€¦    â”† ipedia.org/wiâ€¦    â”†            â”† une rÃ©publiqueâ€¦   â”‚\n",
      "â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "(4498441, 6)\n",
      "shape: (15,)\n",
      "Series: '' [struct[5]]\n",
      "[\n",
      "\t{\"https://fr.wikipedia.org/wiki/alg%C3%A8bre\",2,\"algÃ¨bre\",\"alg%C3%A8bre\",\"algÃ¨bre\"}\n",
      "\t{\"https://fr.wikipedia.org/wiki/math%C3%A9matiques\",100,\"mathÃ©matiques\",\"math%C3%A9matiques\",\"mathÃ©matiques\"}\n",
      "\t{\"https://fr.wikipedia.org/wiki/structure%20alg%C3%A9brique\",200,\"structures algÃ©briques\",\"structure%20alg%C3%A9brique\",\"structure algÃ©brique\"}\n",
      "\t{\"https://fr.wikipedia.org/wiki/Alg%C3%A8bre%20%28math%C3%A9matiques%20%C3%A9l%C3%A9mentaires%29\",353,\"algÃ¨bre Ã©lÃ©mentaire\",\"Alg%C3%A8bre%20%28math%C3%A9matiques%20%C3%A9l%C3%A9mentaires%29\",\"AlgÃ¨bre (mathÃ©matiques Ã©lÃ©mentaires)\"}\n",
      "\t{\"https://fr.wikipedia.org/wiki/calcul%20alg%C3%A9brique\",494,\"calcul algÃ©brique\",\"calcul%20alg%C3%A9brique\",\"calcul algÃ©brique\"}\n",
      "\tâ€¦\n",
      "\t{\"https://fr.wikipedia.org/wiki/Structure%20alg%C3%A9brique\",2012,\"structures algÃ©briques\",\"Structure%20alg%C3%A9brique\",\"Structure algÃ©brique\"}\n",
      "\t{\"https://fr.wikipedia.org/wiki/topologie%20alg%C3%A9brique\",2268,\"topologie algÃ©brique\",\"topologie%20alg%C3%A9brique\",\"topologie algÃ©brique\"}\n",
      "\t{\"https://fr.wikipedia.org/wiki/th%C3%A9orie%20alg%C3%A9brique%20des%20nombres\",2393,\"thÃ©orie algÃ©brique des nombres\",\"th%C3%A9orie%20alg%C3%A9brique%20des%20nombres\",\"thÃ©orie algÃ©brique des nombres\"}\n",
      "\t{\"https://fr.wikipedia.org/wiki/Andrew%20Wiles\",2620,\"Andrew Wiles\",\"Andrew%20Wiles\",\"Andrew Wiles\"}\n",
      "\t{\"https://fr.wikipedia.org/wiki/dernier%20th%C3%A9or%C3%A8me%20de%20Fermat\",2686,\"dernier thÃ©orÃ¨me de Fermat\",\"dernier%20th%C3%A9or%C3%A8me%20de%20Fermat\",\"dernier thÃ©orÃ¨me de Fermat\"}\n",
      "]\n",
      "Angola\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.shape)\n",
    "print(df[\"links\"][2])\n",
    "print(df[\"title\"][32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc8b1106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Creating unbiased link prediction dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [07:33<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  Building semantic similarity features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing similarities: 0it [00:00, ?it/s]/tmp/ipykernel_11470/2553876889.py:17: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Computing similarities: 1000it [01:30, 11.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Creating positive/negative training samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating samples: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 70453.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Training link prediction model...\n",
      "ğŸ“Š Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74       401\n",
      "           1       0.55      0.57      0.56       229\n",
      "\n",
      "    accuracy                           0.67       630\n",
      "   macro avg       0.65      0.65      0.65       630\n",
      "weighted avg       0.68      0.67      0.67       630\n",
      "\n",
      "ğŸ”® Predicting links for: 'AlgÃ¨bre linÃ©aire' (ID: 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11470/1939682050.py:49: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¯ Top 10 predicted links:\n",
      " 1. 'ParallÃ©logramme' (ID: 8727)\n",
      "     Similarity: 0.907, Link Prob: 1.000\n",
      " 2. 'Matrice (mathÃ©matiques)' (ID: 15384)\n",
      "     Similarity: 0.923, Link Prob: 0.980\n",
      " 3. 'GÃ©omÃ©trie' (ID: 1218)\n",
      "     Similarity: 0.923, Link Prob: 0.970\n",
      " 4. 'ConjuguÃ©' (ID: 32037)\n",
      "     Similarity: 0.907, Link Prob: 0.950\n",
      " 5. 'IdÃ©al' (ID: 11001)\n",
      "     Similarity: 0.910, Link Prob: 0.890\n",
      " 6. 'Orbitale atomique' (ID: 35781)\n",
      "     Similarity: 0.906, Link Prob: 0.880\n",
      " 7. 'Ellipse (mathÃ©matiques)' (ID: 18697)\n",
      "     Similarity: 0.904, Link Prob: 0.880\n",
      " 8. 'Analyse rÃ©elle' (ID: 20035)\n",
      "     Similarity: 0.912, Link Prob: 0.870\n",
      " 9. 'Espace vectoriel' (ID: 1051)\n",
      "     Similarity: 0.928, Link Prob: 0.820\n",
      "10. 'IntÃ©gration (mathÃ©matiques)' (ID: 14294)\n",
      "     Similarity: 0.919, Link Prob: 0.820\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create unbiased training dataset\n",
    "training_data = create_link_prediction_dataset(df.head(1000))\n",
    "\n",
    "# Step 2: Build similarity features (using clean text only)\n",
    "similarity_features = build_article_similarity_features(df.head(1000), client, \"wikipedia_fr\")\n",
    "\n",
    "# Step 3: Create positive/negative samples\n",
    "training_samples = create_training_samples(df.head(1000), similarity_features)\n",
    "\n",
    "# Step 4: Train model\n",
    "model, X_test, y_test, y_prob = train_link_prediction_model(training_samples)\n",
    "\n",
    "# Step 5: Predict links for new articles\n",
    "predictions = predict_links_for_article(model, client, 7, df, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4a8d0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Garder que les phrases avec liens hypertextes de chaque article, embedd ces phrases uniquement, et run cosine similarity entre les phrases elle mÃªmes et les articles en entier (ou les phrases hypertextes d'un autre article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7434c9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from typing import Dict, List, Tuple\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, average_precision_score\n",
    "import numpy as np\n",
    "from urllib.parse import quote\n",
    "\n",
    "def create_url_to_id_mapping(df: pl.DataFrame) -> Dict[str, int]:\n",
    "    \"\"\"Create mapping from Wikipedia URLs/titles to article IDs\"\"\"\n",
    "    url_to_id = {}\n",
    "    \n",
    "    for row in df.select([\"id\", \"title\"]).iter_rows(named=True):\n",
    "        article_id = row[\"id\"]\n",
    "        title = row[\"title\"]\n",
    "        \n",
    "        # Create URL-encoded version (like alg%C3%A8bre)\n",
    "        encoded_title = quote(title.replace(\" \", \"_\"), safe=\"\")\n",
    "        \n",
    "        # Create various URL patterns that might appear in href_decoded\n",
    "        patterns = [\n",
    "            title,                                    # Original title\n",
    "            title.replace(\" \", \"_\"),                  # Spaces to underscores\n",
    "            encoded_title,                           # URL encoded (alg%C3%A8bre)\n",
    "            quote(title, safe=\"\"),                   # Fully encoded\n",
    "            title.replace(\" \", \"%20\"),               # Spaces to %20\n",
    "            title.lower(),                           # Lowercase\n",
    "            title.lower().replace(\" \", \"_\"),         # Lowercase with underscores\n",
    "            encoded_title.lower()                    # Lowercase encoded\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            url_to_id[pattern] = article_id\n",
    "    \n",
    "    return url_to_id\n",
    "\n",
    "def extract_true_links_for_article(df: pl.DataFrame, article_id: int, url_to_id: Dict[str, int]) -> List[int]:\n",
    "    \"\"\"Extract true target article IDs from the links array for a given article.\"\"\"\n",
    "    \n",
    "    # Fixed Polars syntax\n",
    "    article_row = df.filter(pl.col(\"id\") == article_id)\n",
    "    if article_row.height == 0:\n",
    "        return []\n",
    "    \n",
    "    # Get links - handle potential None values properly\n",
    "    links_series = article_row.select(\"links\").to_series()\n",
    "    if links_series.is_empty():  # Fixed: use is_empty() instead of direct boolean\n",
    "        return []\n",
    "    \n",
    "    links = links_series[0]\n",
    "    if links is None:  # Handle None case\n",
    "        return []\n",
    "    \n",
    "    true_target_ids = []\n",
    "    \n",
    "    for link in links:\n",
    "        href_decoded = link.get(\"href_decoded\", \"\")\n",
    "        \n",
    "        # Try to map href_decoded to article ID\n",
    "        target_id = None\n",
    "        \n",
    "        # Direct lookup first\n",
    "        if href_decoded in url_to_id:\n",
    "            target_id = url_to_id[href_decoded]\n",
    "        else:\n",
    "            # Try variations\n",
    "            variations = [\n",
    "                href_decoded.replace(\"_\", \" \"),\n",
    "                href_decoded.replace(\"%20\", \" \"),\n",
    "                href_decoded.replace(\"_\", \"%20\"),\n",
    "                quote(href_decoded.replace(\"_\", \" \"), safe=\"\"),  # Re-encode\n",
    "                href_decoded.lower(),\n",
    "                href_decoded.lower().replace(\"_\", \" \"),\n",
    "                href_decoded.lower().replace(\"%20\", \" \")\n",
    "            ]\n",
    "            \n",
    "            for variation in variations:\n",
    "                if variation in url_to_id:\n",
    "                    target_id = url_to_id[variation]\n",
    "                    break\n",
    "        \n",
    "        # Fixed: use proper comparison instead of 'and'\n",
    "        if target_id is not None and target_id != article_id:\n",
    "            true_target_ids.append(target_id)\n",
    "    \n",
    "    return list(set(true_target_ids))  # Remove duplicates\n",
    "\n",
    "def validate_predictions_against_true_links(\n",
    "    model,\n",
    "    client,\n",
    "    df: pl.DataFrame,\n",
    "    collection_name: str = \"wikipedia_fr\",\n",
    "    test_article_ids: List[int] = None,\n",
    "    k_predictions: int = 20,\n",
    "    similarity_threshold: float = 0.5\n",
    "):\n",
    "    \"\"\"Validate link predictions against true hyperlinks from the dataset.\"\"\"\n",
    "    \n",
    "    print(\"ğŸ” Validating predictions against true hyperlinks...\")\n",
    "    \n",
    "    # Create URL to ID mapping\n",
    "    url_to_id = create_url_to_id_mapping(df)\n",
    "    print(f\"ğŸ“š Created mapping for {len(url_to_id)} URL patterns\")\n",
    "    \n",
    "    if test_article_ids is None:\n",
    "        # Fixed: use proper Polars filtering\n",
    "        articles_with_links = df.filter(pl.col(\"link_count\") > 0)\n",
    "        if not articles_with_links.is_empty():  # Fixed: use is_empty()\n",
    "            test_article_ids = articles_with_links.select(\"id\").to_series().to_list()[:100]\n",
    "        else:\n",
    "            test_article_ids = df.select(\"id\").to_series().to_list()[:100]\n",
    "    \n",
    "    validation_results = []\n",
    "    \n",
    "    for article_id in tqdm(test_article_ids, desc=\"Validating articles\"):\n",
    "        try:\n",
    "            # Get true links for this article\n",
    "            true_links = extract_true_links_for_article(df, article_id, url_to_id)\n",
    "            \n",
    "            if not true_links:  # Fixed: direct boolean check is OK for lists\n",
    "                continue\n",
    "            \n",
    "            # Get model predictions\n",
    "            predicted_links = predict_links_for_article_validation(\n",
    "                model, client, article_id, df, collection_name, k_predictions, similarity_threshold\n",
    "            )\n",
    "            \n",
    "            if not predicted_links:  # Fixed: direct boolean check is OK for lists\n",
    "                continue\n",
    "            \n",
    "            # Calculate metrics for this article\n",
    "            metrics = calculate_article_metrics(true_links, predicted_links, k_predictions)\n",
    "            \n",
    "            validation_results.append({\n",
    "                \"article_id\": article_id,\n",
    "                \"article_title\": get_article_title(df, article_id),\n",
    "                \"num_true_links\": len(true_links),\n",
    "                \"num_predictions\": len(predicted_links),\n",
    "                **metrics\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error validating article {article_id}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Calculate aggregate metrics\n",
    "    aggregate_metrics = calculate_aggregate_metrics(validation_results)\n",
    "    \n",
    "    # Print results\n",
    "    print_validation_results(validation_results, aggregate_metrics)\n",
    "    \n",
    "    return validation_results, aggregate_metrics\n",
    "\n",
    "def get_article_title(df: pl.DataFrame, article_id: int) -> str:\n",
    "    \"\"\"Get article title by ID\"\"\"\n",
    "    row = df.filter(pl.col(\"id\") == article_id)\n",
    "    if not row.is_empty():  # Fixed: use is_empty()\n",
    "        return row.select(\"title\").to_series()[0]\n",
    "    return f\"Unknown ID {article_id}\"\n",
    "\n",
    "def predict_links_for_article_validation(\n",
    "    model, client, article_id: int, df: pl.DataFrame, \n",
    "    collection_name: str, k: int, similarity_threshold: float\n",
    ") -> List[int]:\n",
    "    \"\"\"Get model predictions for validation\"\"\"\n",
    "    \n",
    "    # Get article info - Fixed Polars syntax\n",
    "    article_row = df.filter(pl.col(\"id\") == article_id)\n",
    "    if article_row.is_empty():  # Fixed: use is_empty()\n",
    "        return []\n",
    "    \n",
    "    clean_text = article_row.select(\"text_withoutHref\").to_series()[0]\n",
    "    \n",
    "    # Get similar articles (candidates)\n",
    "    try:\n",
    "        similar_articles = client.recommend(\n",
    "            collection_name=collection_name,\n",
    "            positive=[int(article_id)],\n",
    "            limit=k * 2,\n",
    "            with_payload=True\n",
    "        )\n",
    "    except:\n",
    "        # Fallback: encode the clean text\n",
    "        vec = encode_article_text(clean_text)\n",
    "        similar_articles = client.search(\n",
    "            collection_name=collection_name,\n",
    "            query_vector=vec,\n",
    "            limit=k * 2\n",
    "        )\n",
    "    \n",
    "    # Filter and predict\n",
    "    predictions = []\n",
    "    for result in similar_articles:\n",
    "        target_id = result.payload.get(\"id\", result.id)\n",
    "        \n",
    "        # Fixed: use proper comparison\n",
    "        if (int(target_id) != int(article_id) and \n",
    "            result.score >= similarity_threshold):\n",
    "            \n",
    "            # Create feature vector for model\n",
    "            features = np.array([[result.score]])\n",
    "            \n",
    "            try:\n",
    "                prob = model.predict_proba(features)[0][1]\n",
    "                predictions.append({\n",
    "                    \"target_id\": target_id,\n",
    "                    \"similarity_score\": result.score,\n",
    "                    \"link_probability\": prob\n",
    "                })\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    # Sort by link probability and return top-k target IDs\n",
    "    predictions.sort(key=lambda x: x[\"link_probability\"], reverse=True)\n",
    "    return [pred[\"target_id\"] for pred in predictions[:k]]\n",
    "\n",
    "# Rest of the functions remain the same...\n",
    "def calculate_article_metrics(true_links: List[int], predicted_links: List[int], k: int) -> Dict:\n",
    "    \"\"\"Calculate precision, recall, F1 for a single article\"\"\"\n",
    "    \n",
    "    true_set = set(true_links)\n",
    "    pred_set = set(predicted_links)\n",
    "    \n",
    "    tp = len(true_set.intersection(pred_set))\n",
    "    fp = len(pred_set - true_set)\n",
    "    fn = len(true_set - pred_set)\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "    precision_at_k = tp / min(k, len(predicted_links)) if predicted_links else 0.0\n",
    "    recall_at_k = tp / len(true_links) if true_links else 0.0\n",
    "    \n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"precision_at_k\": precision_at_k,\n",
    "        \"recall_at_k\": recall_at_k,\n",
    "        \"true_positives\": tp,\n",
    "        \"false_positives\": fp,\n",
    "        \"false_negatives\": fn\n",
    "    }\n",
    "\n",
    "def calculate_aggregate_metrics(validation_results: List[Dict]) -> Dict:\n",
    "    \"\"\"Calculate aggregate metrics across all articles\"\"\"\n",
    "    \n",
    "    if not validation_results:\n",
    "        return {}\n",
    "    \n",
    "    total_tp = sum(r[\"true_positives\"] for r in validation_results)\n",
    "    total_fp = sum(r[\"false_positives\"] for r in validation_results)\n",
    "    total_fn = sum(r[\"false_negatives\"] for r in validation_results)\n",
    "    \n",
    "    micro_precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0.0\n",
    "    micro_recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0.0\n",
    "    micro_f1 = 2 * (micro_precision * micro_recall) / (micro_precision + micro_recall) if (micro_precision + micro_recall) > 0 else 0.0\n",
    "    \n",
    "    macro_precision = np.mean([r[\"precision\"] for r in validation_results])\n",
    "    macro_recall = np.mean([r[\"recall\"] for r in validation_results])\n",
    "    macro_f1 = np.mean([r[\"f1_score\"] for r in validation_results])\n",
    "    \n",
    "    avg_precision_at_k = np.mean([r[\"precision_at_k\"] for r in validation_results])\n",
    "    avg_recall_at_k = np.mean([r[\"recall_at_k\"] for r in validation_results])\n",
    "    \n",
    "    return {\n",
    "        \"num_articles\": len(validation_results),\n",
    "        \"micro_precision\": micro_precision,\n",
    "        \"micro_recall\": micro_recall,\n",
    "        \"micro_f1\": micro_f1,\n",
    "        \"macro_precision\": macro_precision,\n",
    "        \"macro_recall\": macro_recall,\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"avg_precision_at_k\": avg_precision_at_k,\n",
    "        \"avg_recall_at_k\": avg_recall_at_k,\n",
    "        \"total_true_positives\": total_tp,\n",
    "        \"total_false_positives\": total_fp,\n",
    "        \"total_false_negatives\": total_fn\n",
    "    }\n",
    "\n",
    "def print_validation_results(validation_results: List[Dict], aggregate_metrics: Dict):\n",
    "    \"\"\"Print detailed validation results\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ğŸ¯ LINK PREDICTION VALIDATION RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š AGGREGATE METRICS ({aggregate_metrics['num_articles']} articles):\")\n",
    "    print(f\"   Micro-averaged:\")\n",
    "    print(f\"     Precision: {aggregate_metrics['micro_precision']:.3f}\")\n",
    "    print(f\"     Recall:    {aggregate_metrics['micro_recall']:.3f}\")\n",
    "    print(f\"     F1-Score:  {aggregate_metrics['micro_f1']:.3f}\")\n",
    "    \n",
    "    print(f\"\\n   Macro-averaged:\")\n",
    "    print(f\"     Precision: {aggregate_metrics['macro_precision']:.3f}\")\n",
    "    print(f\"     Recall:    {aggregate_metrics['macro_recall']:.3f}\")\n",
    "    print(f\"     F1-Score:  {aggregate_metrics['macro_f1']:.3f}\")\n",
    "    \n",
    "    print(f\"\\n   Precision@K: {aggregate_metrics['avg_precision_at_k']:.3f}\")\n",
    "    print(f\"   Recall@K:    {aggregate_metrics['avg_recall_at_k']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3d017d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Quick Link Prediction Pipeline\n",
      "ğŸ“š Creating training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11470/4097986851.py:23: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar = client.recommend(collection_name=collection_name, positive=[int(source_id)], limit=20, with_payload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Training model on 2500 samples...\n",
      "ğŸ” Running validation...\n",
      "ğŸ” Validating predictions against true hyperlinks...\n",
      "ğŸ“š Created mapping for 25059409 URL patterns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating articles:   0%|          | 0/100 [00:00<?, ?it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:   1%|          | 1/100 [00:01<01:44,  1.06s/it]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:   2%|â–         | 2/100 [00:01<01:19,  1.23it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:   3%|â–         | 3/100 [00:02<01:10,  1.38it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:   4%|â–         | 4/100 [00:03<01:09,  1.38it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:   5%|â–Œ         | 5/100 [00:03<01:03,  1.50it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:   6%|â–Œ         | 6/100 [00:04<00:58,  1.60it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:   7%|â–‹         | 7/100 [00:04<01:00,  1.53it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:   8%|â–Š         | 8/100 [00:05<01:03,  1.46it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:   9%|â–‰         | 9/100 [00:06<01:00,  1.50it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  10%|â–ˆ         | 10/100 [00:06<00:56,  1.59it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  11%|â–ˆ         | 11/100 [00:07<00:56,  1.56it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  12%|â–ˆâ–        | 12/100 [00:07<00:52,  1.66it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  13%|â–ˆâ–        | 13/100 [00:08<00:53,  1.62it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  14%|â–ˆâ–        | 14/100 [00:09<00:53,  1.61it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  15%|â–ˆâ–Œ        | 15/100 [00:09<00:51,  1.64it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  16%|â–ˆâ–Œ        | 16/100 [00:10<00:52,  1.59it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  17%|â–ˆâ–‹        | 17/100 [00:11<01:06,  1.25it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  18%|â–ˆâ–Š        | 18/100 [00:12<01:15,  1.09it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  19%|â–ˆâ–‰        | 19/100 [00:13<01:09,  1.16it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  20%|â–ˆâ–ˆ        | 20/100 [00:14<01:04,  1.24it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  21%|â–ˆâ–ˆ        | 21/100 [00:15<01:01,  1.28it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  22%|â–ˆâ–ˆâ–       | 22/100 [00:15<00:59,  1.31it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  23%|â–ˆâ–ˆâ–       | 23/100 [00:16<00:54,  1.41it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  24%|â–ˆâ–ˆâ–       | 24/100 [00:17<00:53,  1.42it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  25%|â–ˆâ–ˆâ–Œ       | 25/100 [00:17<00:56,  1.33it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  26%|â–ˆâ–ˆâ–Œ       | 26/100 [00:18<00:58,  1.27it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  27%|â–ˆâ–ˆâ–‹       | 27/100 [00:19<00:49,  1.46it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  28%|â–ˆâ–ˆâ–Š       | 28/100 [00:19<00:47,  1.53it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  29%|â–ˆâ–ˆâ–‰       | 29/100 [00:20<00:43,  1.63it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  30%|â–ˆâ–ˆâ–ˆ       | 30/100 [00:21<00:45,  1.55it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  31%|â–ˆâ–ˆâ–ˆ       | 31/100 [00:21<00:47,  1.45it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [00:22<00:50,  1.35it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  33%|â–ˆâ–ˆâ–ˆâ–      | 33/100 [00:23<00:48,  1.38it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [00:23<00:44,  1.47it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [00:24<00:41,  1.58it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [00:25<00:41,  1.54it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [00:25<00:39,  1.58it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [00:26<00:40,  1.54it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [00:27<00:40,  1.51it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [00:27<00:39,  1.54it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [00:28<00:35,  1.65it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [00:28<00:35,  1.64it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/100 [00:29<00:32,  1.77it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [00:29<00:31,  1.78it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [00:30<00:30,  1.79it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [00:31<00:33,  1.62it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [00:31<00:33,  1.58it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [00:32<00:35,  1.47it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [00:33<00:36,  1.38it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [00:34<00:38,  1.30it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [00:35<00:40,  1.20it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [00:36<00:39,  1.22it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 53/100 [00:36<00:37,  1.27it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [00:37<00:35,  1.30it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [00:38<00:32,  1.37it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [00:38<00:32,  1.35it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [00:39<00:32,  1.32it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [00:40<00:31,  1.32it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [00:41<00:28,  1.42it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [00:41<00:25,  1.56it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [00:42<00:22,  1.70it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [00:42<00:20,  1.85it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 63/100 [00:42<00:19,  1.91it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [00:43<00:18,  1.96it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [00:44<00:18,  1.85it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [00:44<00:18,  1.89it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [00:45<00:16,  1.99it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [00:45<00:17,  1.82it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [00:46<00:18,  1.72it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [00:46<00:16,  1.77it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [00:47<00:16,  1.76it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [00:48<00:17,  1.62it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 73/100 [00:49<00:20,  1.34it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [00:50<00:21,  1.22it/s]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [00:52<00:30,  1.21s/it]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [00:54<00:32,  1.35s/it]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [00:55<00:34,  1.51s/it]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [00:57<00:35,  1.63s/it]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [00:59<00:36,  1.75s/it]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [01:01<00:37,  1.86s/it]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [01:03<00:35,  1.88s/it]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [01:05<00:34,  1.93s/it]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 83/100 [01:08<00:33,  1.98s/it]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [01:10<00:32,  2.02s/it]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [01:11<00:29,  1.95s/it]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [01:13<00:26,  1.87s/it]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [01:17<00:32,  2.49s/it]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [01:24<00:45,  3.81s/it]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [01:27<00:38,  3.54s/it]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [01:29<00:30,  3.05s/it]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [01:30<00:23,  2.59s/it]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [01:32<00:18,  2.29s/it]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 93/100 [01:33<00:13,  1.99s/it]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [01:35<00:11,  1.96s/it]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [01:37<00:10,  2.05s/it]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [01:39<00:07,  1.93s/it]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [01:41<00:05,  1.83s/it]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [01:43<00:03,  1.99s/it]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [01:46<00:02,  2.31s/it]/tmp/ipykernel_11470/3086961291.py:174: DeprecationWarning: `recommend` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  similar_articles = client.recommend(\n",
      "Validating articles: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:49<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ¯ LINK PREDICTION VALIDATION RESULTS\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š AGGREGATE METRICS (100 articles):\n",
      "   Micro-averaged:\n",
      "     Precision: 0.270\n",
      "     Recall:    0.017\n",
      "     F1-Score:  0.033\n",
      "\n",
      "   Macro-averaged:\n",
      "     Precision: 0.270\n",
      "     Recall:    0.049\n",
      "     F1-Score:  0.055\n",
      "\n",
      "   Precision@K: 0.270\n",
      "   Recall@K:    0.049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Complete pipeline - train model and validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Quick training pipeline + validation\n",
    "def quick_link_prediction_pipeline(client, df, collection_name=\"wikipedia_fr\", test_size=100):\n",
    "    print(\"ğŸš€ Quick Link Prediction Pipeline\")\n",
    "    \n",
    "    # Step 1: Create simple training data from similarity scores\n",
    "    print(\"ğŸ“š Creating training data...\")\n",
    "    training_samples = []\n",
    "    url_to_id = create_url_to_id_mapping(df.head(500))  # Use subset for speed\n",
    "    \n",
    "    for row in df.head(200).iter_rows(named=True):  # Small training set\n",
    "        source_id = row[\"id\"]\n",
    "        true_links = extract_true_links_for_article(df, source_id, url_to_id)\n",
    "        \n",
    "        if not true_links:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Get similar articles\n",
    "            similar = client.recommend(collection_name=collection_name, positive=[int(source_id)], limit=20, with_payload=True)\n",
    "            \n",
    "            for result in similar:\n",
    "                target_id = result.payload.get(\"id\", result.id)\n",
    "                if int(target_id) != int(source_id):\n",
    "                    label = 1 if target_id in true_links else 0\n",
    "                    training_samples.append([result.score, label])\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if len(training_samples) < 10:\n",
    "        print(\"âŒ Not enough training samples\")\n",
    "        return None, None\n",
    "    \n",
    "    # Step 2: Train simple model\n",
    "    print(f\"ğŸ¤– Training model on {len(training_samples)} samples...\")\n",
    "    X = np.array([s[0] for s in training_samples]).reshape(-1, 1)\n",
    "    y = np.array([s[1] for s in training_samples])\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Step 3: Validate\n",
    "    print(\"ğŸ” Running validation...\")\n",
    "    validation_results, metrics = validate_predictions_against_true_links(\n",
    "        model=model,\n",
    "        client=client,\n",
    "        df=df,\n",
    "        collection_name=collection_name,\n",
    "        test_article_ids=None,\n",
    "        k_predictions=10,\n",
    "        similarity_threshold=0.3\n",
    "    )\n",
    "    \n",
    "    return validation_results, metrics\n",
    "\n",
    "# ONE-LINER USAGE:\n",
    "validation_results, metrics = quick_link_prediction_pipeline(client, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078ed3f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
